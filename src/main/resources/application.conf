####################################
# Twitter Job Config File #
####################################


spark {
  # The Spark master host. Set first by environment if exists. Then system, then config.
  # Options: spark://host1:port1,host2:port2
  # - "local" to run locally with one thread,
  # - local[4]" to run locally with 4 cores
  # - the master IP/hostname to run on a Spark standalone cluster
  # - if not set, defaults to "local[*]" to run with enough threads
  # Supports optional HA failover for more than one: host1,host2..
  # which is used to inform: spark://host1:port1,host2:port2
  master = ${?SPARK_HA_MASTER}
  cleaner.ttl = ${?SPARK_CLEANER_TTL}

  # The batch interval must be set based on the latency requirements
  # of your application and available cluster resources.
  streaming.batch.interval = ${?SPARK_STREAMING_BATCH_INTERVAL}

  hadoophome = /home/android/spark-1.3.0-bin-hadoop2.4
  checkpoint = /checkpoint/
}


twitter {

  consumerKey = uI7B3xyd3K4CUIKepqwQHseWg
  consumerSecret = oD9trZH8Uoo5te1wekDQChJjeT1TpoDV5q9IFUEXjnxjWPrBEN
  accessToken = 15845598-vA7wJs1UkT3jobdStzFc8ct1KKQnN0vXDeWUqAhqS
  accessTokenSecret = QF4tSREfNkQIzWvieBbF6115Ourz1Dg0cgYUy80ChyCAT

}